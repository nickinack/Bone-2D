{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport tensorflow as tf\n%matplotlib inline\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten \nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.layers import BatchNormalization\nfrom keras import optimizers\nfrom keras import callbacks\nfrom keras.utils import to_categorical\nfrom keras.layers import Activation\nimport cv2\nfrom keras.layers import UpSampling2D\nfrom albumentations import PadIfNeeded\nfrom albumentations import HorizontalFlip\nfrom albumentations import VerticalFlip   \nfrom albumentations import CenterCrop   \nfrom albumentations import Crop\nfrom albumentations import Compose\nfrom albumentations import Transpose\nfrom albumentations import RandomRotate90\nfrom albumentations import Rotate\nfrom albumentations import RandomSizedCrop\nfrom albumentations import OneOf\nfrom albumentations import CLAHE\nfrom albumentations import RandomBrightnessContrast    \nfrom albumentations import RandomGamma \nfrom keras.applications import vgg19\nfrom keras import layers\nfrom keras import models\nimport keras.backend as K\nfrom keras.applications.vgg19 import VGG19\nfrom IPython.display import Image, display\nfrom keras.models import Model\nfrom keras.callbacks import History \nhistory = History()\nfrom pathlib import Path\nimport keras\ntf.compat.v1.disable_eager_execution()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":" ## Extract and analyse files "},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nFor given set of images, map the DRR's to masks\n'''\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', -1)\npath = Path(\"../input/digitally-reconstructed-radiographs-drr-bones\")\ndrr = list(map(str, list(path.glob(\"**/*.png\"))))\nbone_drr = pd.DataFrame([(x, x.replace('.png','_mask.png')) for x in drr if not x.endswith('_mask.png')])\nbone_drr.columns = ['image','bones']\nbone_drr.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analyse image and their masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(bone_drr['image'][0])\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img1 = cv2.imread(bone_drr['bones'][0])\nplt.imshow(img1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(bone_drr['image'][1])\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(bone_drr['bones'][1])\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test train split"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 1000\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nbone_drr = bone_drr.sample(frac=1, random_state=seed)\nbone_drr_train = bone_drr[:160].reset_index(drop=True)\nbone_drr_test = bone_drr[160:].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bone_drr_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bone_drr_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = []\ny_train = []\nx_test  = []\ny_test  = []\nfor i in range(len(bone_drr_train)):\n    img = cv2.imread(bone_drr_train['image'][i] , 0)\n    img = cv2.resize(img,(512,512))\n    img = img.astype(np.float32)\n    img-=img.mean()\n    img/=img.std()\n    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n    x_train.append(img)\n    mask = cv2.imread(bone_drr_test['bones'][1])\n    mask = mask/255\n    mask = cv2.resize(mask,(512,512))\n    y_train.append(mask)\nfor i in range(len(bone_drr_test)):\n    img = cv2.imread(bone_drr_test['image'][i] , 0)\n    img = cv2.resize(img,(512,512))\n    img = img.astype(np.float32)\n    img-=img.mean()\n    img/=img.std()\n    img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n    mask = cv2.imread(bone_drr_test['bones'][1])\n    mask = mask/255\n    mask = cv2.resize(mask,(512,512))\n    x_test.append(img)\n    y_test.append(mask)\nx_train = np.array(x_train)\ny_train = np.array(y_train)\nx_test  = np.array(x_test)\ny_test  = np.array(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.shape(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(x_train[100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(y_train[100])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Build UNET Model\n\nSpecifications of UNET dilations: https://arxiv.org/pdf/2003.10839.pdf"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_shape = (512,512,3)\ninput_img = layers.Input(img_shape)\nl11 = layers.Conv2D(44,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(input_img)\nl11 = layers.Conv2D(44,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(input_img)\nl13 = layers.MaxPooling2D(strides=(2,2) , pool_size=((2,2)))(l11)\n\nl21 = layers.Conv2D(88,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(l13)\nl21 = layers.Conv2D(88,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(l13)\nl23 = layers.MaxPooling2D(strides=(2,2) , pool_size=((2,2)))(l21)\n\nl31 = layers.Conv2D(176,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(l23)\nl31 = layers.Conv2D(176,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(l31)\nl33 = layers.MaxPooling2D(strides=(2,2) , pool_size=((2,2)))(l31)\n\nd1 = layers.Conv2D(176,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(l33)\nd2 = layers.Conv2D(176,kernel_size=3,dilation_rate=2,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(l33)\nd3 = layers.add([d1 , d2])\nu1 = layers.UpSampling2D((2,2))(d3)\n\nu1 = layers.Conv2D(88,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u1)\nu1 = layers.concatenate([l31 , u1])\nu1 = layers.Conv2D(88,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u1)\nu1 = layers.Conv2D(88,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u1)\n\nu2 = layers.UpSampling2D((2, 2))(u1)\nu2 = layers.Conv2D(44,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u2)\nu2 = layers.concatenate([l21 , u2])\nu2 = layers.Conv2D(44,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u2)\nu2 = layers.Conv2D(44,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u2)\n\nu3 = layers.UpSampling2D((2, 2))(u2)\nu3 = layers.Conv2D(22,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u3)\nu3 = layers.concatenate([l11 , u3])\nu3 = layers.Conv2D(22,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u3)\nu3 = layers.Conv2D(22,kernel_size=3,dilation_rate=1,kernel_initializer=\"he_normal\",padding=\"same\",activation=\"relu\")(u3)\n\noutput_layer = layers.Conv2D(1,1,activation=\"tanh\")(u3)\nmodel = Model(inputs = input_img , outputs = output_layer)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Calculate Loss using VGG-19"},{"metadata":{"trusted":true},"cell_type":"code","source":"img = keras.utils.model_to_dot(\n    model,\n    show_shapes=True,\n    expand_nested=True\n)\npdot = Image(img.create_png())\ndisplay(pdot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg19_model = VGG19(include_top=False, weights=\"imagenet\", input_shape=(512,512, 3))\nloss_model = models.Model(inputs=vgg19_model.input , outputs=vgg19_model.get_layer(\"block3_conv3\").output)\nloss_model.trainable = False\ndef vgg_loss(y_true, y_pred):\n    y_pred = tf.image.grayscale_to_rgb(y_pred,name=None)\n    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\nloss_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = keras.utils.model_to_dot(\n    loss_model,\n    show_shapes=True,\n    expand_nested=True\n)\npdot = Image(img.create_png())\ndisplay(pdot)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"adam\", loss=vgg_loss , metrics=[vgg_loss])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    horizontal_flip=True,\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    rescale=1.0,\n    zoom_range=0.2,\n    fill_mode=\"nearest\",\n    cval=0,\n)\ntest_gen = ImageDataGenerator(rescale=1.0)\nbatch_size = 4\ntsteps_per_epoch = np.shape(x_train)[0] + batch_size - 1\nvsteps_per_epoch = np.shape(x_test)[0] + batch_size - 1\nepoch_info = model.fit(x_train,y_train, steps_per_epoch=tsteps_per_epoch ,epochs=100, validation_data=test_gen.flow(x_test,y_test,batch_size=batch_size),validation_steps=vsteps_per_epoch , callbacks=[history])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(epoch_info.info)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"img = x_test[1]\npred = model.predict(img)\npred = model.resize(pred , (512,512))\nplt.imshow(pred)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}